{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CUDA_Sheet4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+3pYtjJA0tKCEtay8jP0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohilrao/Py4DS/blob/main/CUDA_Sheet4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm1ZiQenkUwe"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Jfp64Lkf7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd8b83e-08cb-4712-c34f-033f35761466"
      },
      "source": [
        "batch_size = 64\r\n",
        "n_iters = 30000\r\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "train_dataset = dsets.CIFAR10('./data', train=True, download=True, transform=transform)\r\n",
        " \r\n",
        "test_dataset = dsets.CIFAR10('./data', train=False, download=True, transform=transform)\r\n",
        " \r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)\r\n",
        " \r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCImsWj2uEcx"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn5znL9cklYT"
      },
      "source": [
        "class CNNModel(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(CNNModel, self).__init__()\r\n",
        "         \r\n",
        "        # Convolution 1\r\n",
        "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0)\r\n",
        "        self.relu1 = nn.ReLU()\r\n",
        "         \r\n",
        "        # Max pool 1\r\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\r\n",
        "      \r\n",
        "        # Convolution 2\r\n",
        "        self.cnn2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\r\n",
        "        self.relu2 = nn.ReLU()\r\n",
        "         \r\n",
        "        # Max pool 2\r\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\r\n",
        "\r\n",
        "        # Convolution 3\r\n",
        "        self.cnn3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0)\r\n",
        "        self.relu3 = nn.ReLU()\r\n",
        "\r\n",
        "        # Max pool 3\r\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\r\n",
        "         \r\n",
        "         \r\n",
        "        # Fully connected 1 (readout)\r\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 128)\r\n",
        "\r\n",
        "        # FUlly connected 2       \r\n",
        "        self.fc2 = nn.Linear(128, 10) \r\n",
        "\r\n",
        "        # Dropout\r\n",
        "        self.Dropout = nn.Dropout(0.2)\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        # x =  torch.Size([100, 3, 32, 32])\r\n",
        "        # Convolution 1\r\n",
        "\r\n",
        "       \r\n",
        "        out = self.cnn1(x) #torch.Size([100, 32, 30, 30])\r\n",
        "        out = self.relu1(out) #torch.Size([100, 32, 30, 30 ])\r\n",
        "         \r\n",
        "        # Max pool 1\r\n",
        "        out = self.pool1(out) #torch.Size([100, 32, 15, 15])\r\n",
        "\r\n",
        "        # Dropout after firstlayer\r\n",
        "        out = self.Dropout(out)\r\n",
        "\r\n",
        "        # Convolution 2 \r\n",
        "        out = self.cnn2(out) #torch.Size([100, 64, 13, 13])\r\n",
        "        out = self.relu2(out) #torch.Size([100, 64, 13, 13])\r\n",
        "     \r\n",
        "        # Max pool 2 \r\n",
        "        out = self.pool2(out) #torch.Size([100, 64, 6, 6])\r\n",
        "    \r\n",
        "        out = self.Dropout(out) \r\n",
        "\r\n",
        "        # Convolution 3\r\n",
        "        out = self.cnn3(out) #torch.Size([100, 128, 4, 4])\r\n",
        "        out = self.relu3(out) #torch.Size([100, 128, 4, 4])\r\n",
        "     \r\n",
        "        # Max pool 2 \r\n",
        "        out = self.pool3(out) #torch.Size([100, 128, 2, 2])\r\n",
        "    \r\n",
        "        out = self.Dropout(out) \r\n",
        "\r\n",
        "        out = out.view(out.size(0), -1)   #torch.Size([100, 512])\r\n",
        "\r\n",
        "        \r\n",
        " \r\n",
        "        # Linear function (readout)\r\n",
        "        out = self.fc1(out)\r\n",
        "        out = self.Dropout(out)\r\n",
        "        out = self.fc2(out)\r\n",
        "         \r\n",
        "        return out"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEk-fIHlkp20"
      },
      "source": [
        "model = CNNModel()\r\n",
        " \r\n",
        "#######################\r\n",
        "#  USE GPU FOR MODEL  #\r\n",
        "#######################\r\n",
        " \r\n",
        "if torch.cuda.is_available():\r\n",
        "    model.cuda()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqkBCH0Qkrsy"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVaaEmrkuCn"
      },
      "source": [
        "learning_rate = 0.001\r\n",
        " \r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ax6Jj-t-w9"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HbWEuYukwE_",
        "outputId": "11ddbfbd-6276-4e15-922c-3da527a8c6b1"
      },
      "source": [
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "         \r\n",
        "        #######################\r\n",
        "        #  USE GPU FOR MODEL  #\r\n",
        "        #######################\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            images = images.cuda()\r\n",
        "            labels = labels.cuda()\r\n",
        "        \r\n",
        "        #print(images.shape)\r\n",
        "        #print(labels.shape)\r\n",
        "\r\n",
        "         \r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "         \r\n",
        "        # Forward pass to get output/logits\r\n",
        "        outputs = model(images)\r\n",
        "         \r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "         \r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "         \r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "         \r\n",
        "        iter += 1\r\n",
        "         \r\n",
        "        if iter % 500 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "                #######################\r\n",
        "                #  USE GPU FOR MODEL  #\r\n",
        "                #######################\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    images = images.cuda()\r\n",
        "                 \r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "                 \r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs.data, 1)\r\n",
        "                 \r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "                 \r\n",
        "                # Total correct predictions\r\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().float()\r\n",
        "\r\n",
        "             \r\n",
        "            accuracy = 100. * correct / total\r\n",
        "             \r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 1.4304972887039185. Accuracy: 48.36000061035156\n",
            "Iteration: 1000. Loss: 1.1633632183074951. Accuracy: 53.54999923706055\n",
            "Iteration: 1500. Loss: 1.0777140855789185. Accuracy: 59.04999923706055\n",
            "Iteration: 2000. Loss: 0.8869807720184326. Accuracy: 58.900001525878906\n",
            "Iteration: 2500. Loss: 0.8831294178962708. Accuracy: 63.849998474121094\n",
            "Iteration: 3000. Loss: 1.1146085262298584. Accuracy: 65.4000015258789\n",
            "Iteration: 3500. Loss: 0.9344459176063538. Accuracy: 66.05999755859375\n",
            "Iteration: 4000. Loss: 0.9461567997932434. Accuracy: 66.6500015258789\n",
            "Iteration: 4500. Loss: 1.0535328388214111. Accuracy: 66.7699966430664\n",
            "Iteration: 5000. Loss: 0.8243972063064575. Accuracy: 67.61000061035156\n",
            "Iteration: 5500. Loss: 0.6755139231681824. Accuracy: 68.05000305175781\n",
            "Iteration: 6000. Loss: 0.6112372875213623. Accuracy: 68.72000122070312\n",
            "Iteration: 6500. Loss: 0.9604078531265259. Accuracy: 68.9800033569336\n",
            "Iteration: 7000. Loss: 0.6965226531028748. Accuracy: 68.12000274658203\n",
            "Iteration: 7500. Loss: 0.740287184715271. Accuracy: 69.44000244140625\n",
            "Iteration: 8000. Loss: 0.9831178784370422. Accuracy: 68.5199966430664\n",
            "Iteration: 8500. Loss: 0.6751559972763062. Accuracy: 70.1500015258789\n",
            "Iteration: 9000. Loss: 0.5401370525360107. Accuracy: 70.16999816894531\n",
            "Iteration: 9500. Loss: 0.8818429112434387. Accuracy: 70.7300033569336\n",
            "Iteration: 10000. Loss: 0.9829482436180115. Accuracy: 69.55000305175781\n",
            "Iteration: 10500. Loss: 0.6239131093025208. Accuracy: 69.77999877929688\n",
            "Iteration: 11000. Loss: 0.9552370309829712. Accuracy: 70.12000274658203\n",
            "Iteration: 11500. Loss: 0.6798139214515686. Accuracy: 70.04000091552734\n",
            "Iteration: 12000. Loss: 0.8367931842803955. Accuracy: 71.70999908447266\n",
            "Iteration: 12500. Loss: 0.94516521692276. Accuracy: 71.0\n",
            "Iteration: 13000. Loss: 0.6331374049186707. Accuracy: 71.0199966430664\n",
            "Iteration: 13500. Loss: 0.6115208268165588. Accuracy: 71.23999786376953\n",
            "Iteration: 14000. Loss: 0.6187189221382141. Accuracy: 70.83999633789062\n",
            "Iteration: 14500. Loss: 0.7283081412315369. Accuracy: 70.98999786376953\n",
            "Iteration: 15000. Loss: 0.7833135724067688. Accuracy: 71.52999877929688\n",
            "Iteration: 15500. Loss: 0.7005668878555298. Accuracy: 70.37999725341797\n",
            "Iteration: 16000. Loss: 0.8802365064620972. Accuracy: 70.9800033569336\n",
            "Iteration: 16500. Loss: 0.6024965047836304. Accuracy: 72.0199966430664\n",
            "Iteration: 17000. Loss: 0.6629340052604675. Accuracy: 71.48999786376953\n",
            "Iteration: 17500. Loss: 0.6683664321899414. Accuracy: 72.25\n",
            "Iteration: 18000. Loss: 0.739458441734314. Accuracy: 71.36000061035156\n",
            "Iteration: 18500. Loss: 0.6874890327453613. Accuracy: 71.4000015258789\n",
            "Iteration: 19000. Loss: 0.7012718915939331. Accuracy: 71.48999786376953\n",
            "Iteration: 19500. Loss: 0.6293131709098816. Accuracy: 71.61000061035156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8hBtvhk6dx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}